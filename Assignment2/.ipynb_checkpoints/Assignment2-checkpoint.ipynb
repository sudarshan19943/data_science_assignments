{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups = fetch_20newsgroups()\n",
    "newsgroups.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
      "3387\n"
     ]
    }
   ],
   "source": [
    "categories = ['alt.atheism','talk.religion.misc','comp.graphics','sci.space']\n",
    "newsgroups = fetch_20newsgroups(categories=categories, subset='all')\n",
    "print(list(newsgroups.target_names))\n",
    "print(len(newsgroups.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('From', 'IN'), ('healta', 'JJ'), ('saturn', 'NN'), ('wwc', 'NN'), ('edu', 'NN'), ('Tammy', 'NNP'), ('R', 'NNP'), ('Healy', 'NNP'), ('Subject', 'NNP'), ('Re', 'NNP'), ('who', 'WP'), ('are', 'VBP'), ('we', 'PRP'), ('to', 'TO'), ('judge', 'VB'), ('Bobby', 'NNP'), ('Lines', 'NNPS'), ('Organization', 'NNP'), ('Walla', 'NNP'), ('Walla', 'NNP'), ('College', 'NNP'), ('Lines', 'NNP'), ('In', 'IN'), ('article', 'NN'), ('Apr', 'NNP'), ('ultb', 'JJ'), ('isc', 'NN'), ('rit', 'NN'), ('edu', 'NN'), ('snm', 'NN'), ('ultb', 'JJ'), ('isc', 'NN'), ('rit', 'NN'), ('edu', 'NN'), ('S', 'NNP'), ('N', 'NNP'), ('Mozumder', 'NNP'), ('writes', 'VBZ'), ('From', 'IN'), ('snm', 'NN'), ('ultb', 'JJ'), ('isc', 'NN'), ('rit', 'NN'), ('edu', 'NN'), ('S', 'NNP'), ('N', 'NNP'), ('Mozumder', 'NNP'), ('Subject', 'NNP'), ('Re', 'NNP'), ('who', 'WP'), ('are', 'VBP'), ('we', 'PRP'), ('to', 'TO'), ('judge', 'VB'), ('Bobby', 'NNP'), ('Date', 'NNP'), ('Wed', 'NNP'), ('Apr', 'NNP'), ('GMT', 'NNP'), ('In', 'IN'), ('article', 'NN'), ('healta', 'NN'), ('saturn', 'NN'), ('wwc', 'NN'), ('edu', 'NN'), ('healta', 'NN'), ('saturn', 'VBP'), ('wwc', 'JJ'), ('edu', 'NN'), ('TAMMY', 'NNP'), ('R', 'NNP'), ('HEALY', 'NNP'), ('writes', 'VBZ'), ('Bobby', 'NNP'), ('I', 'PRP'), ('would', 'MD'), ('like', 'VB'), ('to', 'TO'), ('take', 'VB'), ('the', 'DT'), ('liberty', 'NN'), ('to', 'TO'), ('quote', 'VB'), ('from', 'IN'), ('a', 'DT'), ('Christian', 'JJ'), ('writer', 'NN'), ('named', 'VBN'), ('Ellen', 'NNP'), ('G', 'NNP'), ('White', 'NNP'), ('I', 'PRP'), ('hope', 'VBP'), ('that', 'IN'), ('what', 'WP'), ('she', 'PRP'), ('said', 'VBD'), ('will', 'MD'), ('help', 'VB'), ('you', 'PRP'), ('to', 'TO'), ('edit', 'VB'), ('your', 'PRP$'), ('remarks', 'NNS'), ('in', 'IN'), ('this', 'DT'), ('group', 'NN'), ('in', 'IN'), ('the', 'DT'), ('future', 'NN'), ('Do', 'NNP'), ('not', 'RB'), ('set', 'VB'), ('yourself', 'PRP'), ('as', 'IN'), ('a', 'DT'), ('standard', 'NN'), ('Do', 'NNP'), ('not', 'RB'), ('make', 'VB'), ('your', 'PRP$'), ('opinions', 'NNS'), ('your', 'PRP$'), ('views', 'NNS'), ('of', 'IN'), ('duty', 'NN'), ('your', 'PRP$'), ('interpretations', 'NNS'), ('of', 'IN'), ('scripture', 'NN'), ('a', 'DT'), ('criterion', 'NN'), ('for', 'IN'), ('others', 'NNS'), ('and', 'CC'), ('in', 'IN'), ('your', 'PRP$'), ('heart', 'NN'), ('condemn', 'VB'), ('them', 'PRP'), ('if', 'IN'), ('they', 'PRP'), ('do', 'VBP'), ('not', 'RB'), ('come', 'VB'), ('up', 'RP'), ('to', 'TO'), ('your', 'PRP$'), ('ideal', 'JJ'), ('Thoughts', 'NNPS'), ('Fromthe', 'NNP'), ('Mount', 'NNP'), ('of', 'IN'), ('Blessing', 'NNP'), ('p', 'NN'), ('I', 'PRP'), ('hope', 'VBP'), ('quoting', 'VBG'), ('this', 'DT'), ('doesn', 'NN'), ('t', 'WDT'), ('make', 'VBP'), ('the', 'DT'), ('atheists', 'NNS'), ('gag', 'VBP'), ('but', 'CC'), ('I', 'PRP'), ('think', 'VBP'), ('Ellen', 'NNP'), ('White', 'NNP'), ('put', 'VBD'), ('it', 'PRP'), ('better', 'JJR'), ('than', 'IN'), ('I', 'PRP'), ('could', 'MD'), ('Tammy', 'VB'), ('Point', 'NNP'), ('Peace', 'NNP'), ('Bobby', 'NNP'), ('Mozumder', 'NNP'), ('My', 'NNP'), ('point', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('you', 'PRP'), ('set', 'VBP'), ('up', 'RP'), ('your', 'PRP$'), ('views', 'NNS'), ('as', 'IN'), ('the', 'DT'), ('only', 'JJ'), ('way', 'NN'), ('to', 'TO'), ('believe', 'VB'), ('Saying', 'VBG'), ('that', 'IN'), ('all', 'DT'), ('eveil', 'NN'), ('in', 'IN'), ('this', 'DT'), ('world', 'NN'), ('is', 'VBZ'), ('caused', 'VBN'), ('by', 'IN'), ('atheism', 'NN'), ('is', 'VBZ'), ('ridiculous', 'JJ'), ('and', 'CC'), ('counterproductive', 'JJ'), ('to', 'TO'), ('dialogue', 'VB'), ('in', 'IN'), ('this', 'DT'), ('newsgroups', 'NN'), ('I', 'PRP'), ('see', 'VBP'), ('in', 'IN'), ('your', 'PRP$'), ('posts', 'NNS'), ('a', 'DT'), ('spirit', 'NN'), ('of', 'IN'), ('condemnation', 'NN'), ('of', 'IN'), ('the', 'DT'), ('atheists', 'NNS'), ('in', 'IN'), ('this', 'DT'), ('newsgroup', 'NN'), ('bacause', 'IN'), ('they', 'PRP'), ('don', 'VBP'), ('t', 'JJ'), ('believe', 'VBP'), ('exactly', 'RB'), ('as', 'IN'), ('you', 'PRP'), ('do', 'VBP'), ('If', 'IN'), ('you', 'PRP'), ('re', 'VBP'), ('here', 'RB'), ('to', 'TO'), ('try', 'VB'), ('to', 'TO'), ('convert', 'VB'), ('the', 'DT'), ('atheists', 'NNS'), ('here', 'RB'), ('you', 'PRP'), ('re', 'VBP'), ('failing', 'VBG'), ('miserably', 'RB'), ('Who', 'WP'), ('wants', 'VBZ'), ('to', 'TO'), ('be', 'VB'), ('in', 'IN'), ('position', 'NN'), ('of', 'IN'), ('constantly', 'RB'), ('defending', 'VBG'), ('themselves', 'PRP'), ('agaist', 'JJ'), ('insulting', 'VBG'), ('attacks', 'NNS'), ('like', 'IN'), ('you', 'PRP'), ('seem', 'VBP'), ('to', 'TO'), ('like', 'VB'), ('to', 'TO'), ('do', 'VB'), ('I', 'PRP'), ('m', 'VB'), ('sorry', 'NN'), ('you', 'PRP'), ('re', 'VBP'), ('so', 'RB'), ('blind', 'IN'), ('that', 'IN'), ('you', 'PRP'), ('didn', 'VBP'), ('t', 'JJ'), ('get', 'VB'), ('the', 'DT'), ('messgae', 'NN'), ('in', 'IN'), ('the', 'DT'), ('quote', 'NN'), ('everyone', 'NN'), ('else', 'RB'), ('has', 'VBZ'), ('seemed', 'VBN'), ('to', 'TO'), ('Tammy', 'VB')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokens = []\n",
    "tokenizer = RegexpTokenizer(r'[^_\\W0-9]+')\n",
    "tokens = [tokenizer.tokenize(token) for token in newsgroups.data]\n",
    "pos_tagged_words = [nltk.pos_tag(token) for token in tokens]\n",
    "print(pos_tagged_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>pmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(AAO, AngloAustralian)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>(charIMAGEHEIGHT, IMAGEWIDTHOriginalImagefp)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>(ccraignmtedu, Catherine)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>(censoring, overbearing)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>(cerebral, edema)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>(ceremonially, unclean)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>(chandrabpasbicom, Chandra)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>(chandrasbicom, jonsbicom)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>(chaveycswiscedu, Darrah)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>(SnapshoT, explorer)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>(checksum, Unique)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>(chemscn, ppmblend)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>(chipset, HWfuncs)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>(chprismgatechEDU, claye)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>(chrono, logy)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>(cindysolansolanunitno, Cynthia)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>(cbsb, ZfZfZn)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>(caustic, boob)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>(catching, snowflakes)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>(casa, cbsb)</td>\n",
       "      <td>19.916301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            bigram        pmi\n",
       "0                           (AAO, AngloAustralian)  19.916301\n",
       "1453  (charIMAGEHEIGHT, IMAGEWIDTHOriginalImagefp)  19.916301\n",
       "1447                     (ccraignmtedu, Catherine)  19.916301\n",
       "1448                      (censoring, overbearing)  19.916301\n",
       "1449                             (cerebral, edema)  19.916301\n",
       "1450                       (ceremonially, unclean)  19.916301\n",
       "1451                   (chandrabpasbicom, Chandra)  19.916301\n",
       "1452                    (chandrasbicom, jonsbicom)  19.916301\n",
       "1454                     (chaveycswiscedu, Darrah)  19.916301\n",
       "1088                          (SnapshoT, explorer)  19.916301\n",
       "1455                            (checksum, Unique)  19.916301\n",
       "1456                           (chemscn, ppmblend)  19.916301\n",
       "1457                            (chipset, HWfuncs)  19.916301\n",
       "1458                     (chprismgatechEDU, claye)  19.916301\n",
       "1459                                (chrono, logy)  19.916301\n",
       "1460              (cindysolansolanunitno, Cynthia)  19.916301\n",
       "1446                                (cbsb, ZfZfZn)  19.916301\n",
       "1445                               (caustic, boob)  19.916301\n",
       "1444                        (catching, snowflakes)  19.916301\n",
       "1443                                  (casa, cbsb)  19.916301"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "text = ''.join(newsgroups.data)\n",
    "text = re.sub('[^\\\\sA-Za-z]+', '', text)\n",
    "word_tokens = nltk.wordpunct_tokenize(text)\n",
    "finder = BigramCollocationFinder.from_words(word_tokens)\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "pmi_df = pd.DataFrame(list(finder.score_ngrams(bigram_measures.pmi)), columns=['bigram', 'pmi']).sort_values(by='pmi', ascending=False)\n",
    "pmi_df.head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>chi-sq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(AAAA, BBBB)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>(coelomate, deuterostome)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>(charIMAGEHEIGHT, IMAGEWIDTHOriginalImagefp)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>(charles, boesel)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>(charsetiso, ContentTransferEncoding)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>(chaveycswiscedu, Darrah)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>(checksum, Unique)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>(chemscn, ppmblend)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>(chipset, HWfuncs)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>(chprismgatechEDU, claye)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>(chrono, logy)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>(cicerocsumassedu, texturetemp)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>(cindysolansolanunitno, Cynthia)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>(cipant, Completed)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>(civillian, casualites)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>(cjkCsyGKonetcomcom, cjknetcomcom)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>(claicerintintinColoradoEDU, Farmer)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>(clements, ukacoxvax)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>(cliche, derision)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>(climatologist, Ithink)</td>\n",
       "      <td>989473.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            bigram    chi-sq\n",
       "0                                     (AAAA, BBBB)  989473.0\n",
       "2097                     (coelomate, deuterostome)  989473.0\n",
       "2075  (charIMAGEHEIGHT, IMAGEWIDTHOriginalImagefp)  989473.0\n",
       "2076                             (charles, boesel)  989473.0\n",
       "2077         (charsetiso, ContentTransferEncoding)  989473.0\n",
       "2078                     (chaveycswiscedu, Darrah)  989473.0\n",
       "2079                            (checksum, Unique)  989473.0\n",
       "2080                           (chemscn, ppmblend)  989473.0\n",
       "2081                            (chipset, HWfuncs)  989473.0\n",
       "2082                     (chprismgatechEDU, claye)  989473.0\n",
       "2083                                (chrono, logy)  989473.0\n",
       "2084               (cicerocsumassedu, texturetemp)  989473.0\n",
       "2085              (cindysolansolanunitno, Cynthia)  989473.0\n",
       "2086                           (cipant, Completed)  989473.0\n",
       "2087                       (civillian, casualites)  989473.0\n",
       "2088            (cjkCsyGKonetcomcom, cjknetcomcom)  989473.0\n",
       "2089          (claicerintintinColoradoEDU, Farmer)  989473.0\n",
       "2090                         (clements, ukacoxvax)  989473.0\n",
       "2091                            (cliche, derision)  989473.0\n",
       "2092                       (climatologist, Ithink)  989473.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_sq_df = pd.DataFrame(list(finder.score_ngrams(bigram_measures.chi_sq)), columns=['bigram', 'chi-sq']).sort_values(by='chi-sq',ascending=False)\n",
    "chi_sq_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>filtered-freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(of, the)</td>\n",
       "      <td>0.005465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(in, the)</td>\n",
       "      <td>0.003126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Subject, Re)</td>\n",
       "      <td>0.002459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(In, article)</td>\n",
       "      <td>0.001982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(to, the)</td>\n",
       "      <td>0.001876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(to, be)</td>\n",
       "      <td>0.001722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(on, the)</td>\n",
       "      <td>0.001672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(is, a)</td>\n",
       "      <td>0.001525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(for, the)</td>\n",
       "      <td>0.001306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(it, is)</td>\n",
       "      <td>0.001293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(that, the)</td>\n",
       "      <td>0.001270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(and, the)</td>\n",
       "      <td>0.001130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(is, the)</td>\n",
       "      <td>0.001065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(Lines, In)</td>\n",
       "      <td>0.001025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(I, have)</td>\n",
       "      <td>0.000973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(from, the)</td>\n",
       "      <td>0.000947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(is, not)</td>\n",
       "      <td>0.000937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(with, the)</td>\n",
       "      <td>0.000918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(of, a)</td>\n",
       "      <td>0.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(University, of)</td>\n",
       "      <td>0.000860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              bigram  filtered-freq\n",
       "0          (of, the)       0.005465\n",
       "1          (in, the)       0.003126\n",
       "2      (Subject, Re)       0.002459\n",
       "3      (In, article)       0.001982\n",
       "4          (to, the)       0.001876\n",
       "5           (to, be)       0.001722\n",
       "6          (on, the)       0.001672\n",
       "7            (is, a)       0.001525\n",
       "8         (for, the)       0.001306\n",
       "9           (it, is)       0.001293\n",
       "10       (that, the)       0.001270\n",
       "11        (and, the)       0.001130\n",
       "12         (is, the)       0.001065\n",
       "13       (Lines, In)       0.001025\n",
       "14         (I, have)       0.000973\n",
       "15       (from, the)       0.000947\n",
       "16         (is, not)       0.000937\n",
       "17       (with, the)       0.000918\n",
       "18           (of, a)       0.000897\n",
       "19  (University, of)       0.000860"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.apply_freq_filter(2)\n",
    "\n",
    "raw_freq_with_filter = pd.DataFrame(list(finder.score_ngrams(bigram_measures.raw_freq)), columns=['bigram', 'filtered-freq']).sort_values(by='filtered-freq',ascending=False)\n",
    "raw_freq_with_filter.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>filtered-t-test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(of, the)</td>\n",
       "      <td>59.688562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Subject, Re)</td>\n",
       "      <td>49.135220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(in, the)</td>\n",
       "      <td>46.409497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(In, article)</td>\n",
       "      <td>44.121113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(to, be)</td>\n",
       "      <td>37.401619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(on, the)</td>\n",
       "      <td>34.617501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(it, is)</td>\n",
       "      <td>31.977423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Lines, In)</td>\n",
       "      <td>31.498479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(is, a)</td>\n",
       "      <td>30.966998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(I, have)</td>\n",
       "      <td>28.842104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(I, am)</td>\n",
       "      <td>28.344194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(would, be)</td>\n",
       "      <td>28.009625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(I, dont)</td>\n",
       "      <td>27.889612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(University, of)</td>\n",
       "      <td>27.814304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(is, not)</td>\n",
       "      <td>27.182207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(for, the)</td>\n",
       "      <td>26.172990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(If, you)</td>\n",
       "      <td>25.654366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(from, the)</td>\n",
       "      <td>25.494554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(I, think)</td>\n",
       "      <td>25.262100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(the, same)</td>\n",
       "      <td>25.017155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              bigram  filtered-t-test\n",
       "0          (of, the)        59.688562\n",
       "1      (Subject, Re)        49.135220\n",
       "2          (in, the)        46.409497\n",
       "3      (In, article)        44.121113\n",
       "4           (to, be)        37.401619\n",
       "5          (on, the)        34.617501\n",
       "6           (it, is)        31.977423\n",
       "7        (Lines, In)        31.498479\n",
       "8            (is, a)        30.966998\n",
       "9          (I, have)        28.842104\n",
       "10           (I, am)        28.344194\n",
       "11       (would, be)        28.009625\n",
       "12         (I, dont)        27.889612\n",
       "13  (University, of)        27.814304\n",
       "14         (is, not)        27.182207\n",
       "15        (for, the)        26.172990\n",
       "16         (If, you)        25.654366\n",
       "17       (from, the)        25.494554\n",
       "18        (I, think)        25.262100\n",
       "19       (the, same)        25.017155"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.apply_freq_filter(2)\n",
    "\n",
    "ttest_with_filter = pd.DataFrame(list(finder.score_ngrams(bigram_measures.student_t)), columns=['bigram','filtered-t-test']).sort_values(by='filtered-t-test', ascending=False)\n",
    "ttest_with_filter.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>pmi</th>\n",
       "      <th>bigram</th>\n",
       "      <th>chi-sq</th>\n",
       "      <th>bigram</th>\n",
       "      <th>filtered-t-test</th>\n",
       "      <th>bigram</th>\n",
       "      <th>filtered-freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(AAO, AngloAustralian)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(AAAA, BBBB)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(of, the)</td>\n",
       "      <td>59.688562</td>\n",
       "      <td>(of, the)</td>\n",
       "      <td>0.005465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(ACAD, nffsff)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(AAH, EXAMINER)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(Subject, Re)</td>\n",
       "      <td>49.135220</td>\n",
       "      <td>(in, the)</td>\n",
       "      <td>0.003126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(ACCENT, Accent)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(AAO, AngloAustralian)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(in, the)</td>\n",
       "      <td>46.409497</td>\n",
       "      <td>(Subject, Re)</td>\n",
       "      <td>0.002459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(ACTIVIST, NEWSLETTER)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(ABORTED, ABORT)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(In, article)</td>\n",
       "      <td>44.121113</td>\n",
       "      <td>(In, article)</td>\n",
       "      <td>0.001982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(ACTIVITY, Cary)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(ABPSoft, mehl)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(to, be)</td>\n",
       "      <td>37.401619</td>\n",
       "      <td>(to, the)</td>\n",
       "      <td>0.001876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(AEA, GEGno)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(ACAD, nffsff)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(on, the)</td>\n",
       "      <td>34.617501</td>\n",
       "      <td>(to, be)</td>\n",
       "      <td>0.001722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(AEAyesBEBno, GEGyes)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(ACCENT, Accent)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(it, is)</td>\n",
       "      <td>31.977423</td>\n",
       "      <td>(on, the)</td>\n",
       "      <td>0.001672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(AFDDBEFgargravarrccutexasedu, XXXDate)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(ACTIVIST, NEWSLETTER)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(Lines, In)</td>\n",
       "      <td>31.498479</td>\n",
       "      <td>(is, a)</td>\n",
       "      <td>0.001525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(AGE, GLORY)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(ACTIVITY, Cary)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(is, a)</td>\n",
       "      <td>30.966998</td>\n",
       "      <td>(for, the)</td>\n",
       "      <td>0.001306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(AKIRA, KIMURA)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(ADMINISTRATION, PASADENA)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(I, have)</td>\n",
       "      <td>28.842104</td>\n",
       "      <td>(it, is)</td>\n",
       "      <td>0.001293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(ALh, Int)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(ADRG, Arc)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(I, am)</td>\n",
       "      <td>28.344194</td>\n",
       "      <td>(that, the)</td>\n",
       "      <td>0.001270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(AMMAIR, CHGSVAXBSTRATHCLYDEACUK)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(AEA, GEGno)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(would, be)</td>\n",
       "      <td>28.009625</td>\n",
       "      <td>(and, the)</td>\n",
       "      <td>0.001130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(AMPHIBOLY, Amphiboly)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(AEAyesBEBno, GEGyes)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(I, dont)</td>\n",
       "      <td>27.889612</td>\n",
       "      <td>(is, the)</td>\n",
       "      <td>0.001065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(AMiga, valcsulxweberedu)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(AFDDBEFgargravarrccutexasedu, XXXDate)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(University, of)</td>\n",
       "      <td>27.814304</td>\n",
       "      <td>(Lines, In)</td>\n",
       "      <td>0.001025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(ANDERE, BELANGSTELLENDEN)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(AGE, GLORY)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(is, not)</td>\n",
       "      <td>27.182207</td>\n",
       "      <td>(I, have)</td>\n",
       "      <td>0.000973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(ANIMATED, MOVIE)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(AHMEDIYE, RISALESI)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(for, the)</td>\n",
       "      <td>26.172990</td>\n",
       "      <td>(from, the)</td>\n",
       "      <td>0.000947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(ANS, Topical)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(AKIRA, KIMURA)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(If, you)</td>\n",
       "      <td>25.654366</td>\n",
       "      <td>(is, not)</td>\n",
       "      <td>0.000937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(APM, Attached)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(ALCFH, WPAFB)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(from, the)</td>\n",
       "      <td>25.494554</td>\n",
       "      <td>(with, the)</td>\n",
       "      <td>0.000918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(APPROACH, DATABASE)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(ALMIGHTY, WHO)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(I, think)</td>\n",
       "      <td>25.262100</td>\n",
       "      <td>(of, a)</td>\n",
       "      <td>0.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(APU, Auxiliary)</td>\n",
       "      <td>19.916301</td>\n",
       "      <td>(ALONG, EACH)</td>\n",
       "      <td>989473.0</td>\n",
       "      <td>(the, same)</td>\n",
       "      <td>25.017155</td>\n",
       "      <td>(University, of)</td>\n",
       "      <td>0.000860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     bigram        pmi  \\\n",
       "0                    (AAO, AngloAustralian)  19.916301   \n",
       "1                            (ACAD, nffsff)  19.916301   \n",
       "2                          (ACCENT, Accent)  19.916301   \n",
       "3                    (ACTIVIST, NEWSLETTER)  19.916301   \n",
       "4                          (ACTIVITY, Cary)  19.916301   \n",
       "5                              (AEA, GEGno)  19.916301   \n",
       "6                     (AEAyesBEBno, GEGyes)  19.916301   \n",
       "7   (AFDDBEFgargravarrccutexasedu, XXXDate)  19.916301   \n",
       "8                              (AGE, GLORY)  19.916301   \n",
       "9                           (AKIRA, KIMURA)  19.916301   \n",
       "10                               (ALh, Int)  19.916301   \n",
       "11        (AMMAIR, CHGSVAXBSTRATHCLYDEACUK)  19.916301   \n",
       "12                   (AMPHIBOLY, Amphiboly)  19.916301   \n",
       "13                (AMiga, valcsulxweberedu)  19.916301   \n",
       "14               (ANDERE, BELANGSTELLENDEN)  19.916301   \n",
       "15                        (ANIMATED, MOVIE)  19.916301   \n",
       "16                           (ANS, Topical)  19.916301   \n",
       "17                          (APM, Attached)  19.916301   \n",
       "18                     (APPROACH, DATABASE)  19.916301   \n",
       "19                         (APU, Auxiliary)  19.916301   \n",
       "\n",
       "                                     bigram    chi-sq            bigram  \\\n",
       "0                              (AAAA, BBBB)  989473.0         (of, the)   \n",
       "1                           (AAH, EXAMINER)  989473.0     (Subject, Re)   \n",
       "2                    (AAO, AngloAustralian)  989473.0         (in, the)   \n",
       "3                          (ABORTED, ABORT)  989473.0     (In, article)   \n",
       "4                           (ABPSoft, mehl)  989473.0          (to, be)   \n",
       "5                            (ACAD, nffsff)  989473.0         (on, the)   \n",
       "6                          (ACCENT, Accent)  989473.0          (it, is)   \n",
       "7                    (ACTIVIST, NEWSLETTER)  989473.0       (Lines, In)   \n",
       "8                          (ACTIVITY, Cary)  989473.0           (is, a)   \n",
       "9                (ADMINISTRATION, PASADENA)  989473.0         (I, have)   \n",
       "10                              (ADRG, Arc)  989473.0           (I, am)   \n",
       "11                             (AEA, GEGno)  989473.0       (would, be)   \n",
       "12                    (AEAyesBEBno, GEGyes)  989473.0         (I, dont)   \n",
       "13  (AFDDBEFgargravarrccutexasedu, XXXDate)  989473.0  (University, of)   \n",
       "14                             (AGE, GLORY)  989473.0         (is, not)   \n",
       "15                     (AHMEDIYE, RISALESI)  989473.0        (for, the)   \n",
       "16                          (AKIRA, KIMURA)  989473.0         (If, you)   \n",
       "17                           (ALCFH, WPAFB)  989473.0       (from, the)   \n",
       "18                          (ALMIGHTY, WHO)  989473.0        (I, think)   \n",
       "19                            (ALONG, EACH)  989473.0       (the, same)   \n",
       "\n",
       "    filtered-t-test            bigram  filtered-freq  \n",
       "0         59.688562         (of, the)       0.005465  \n",
       "1         49.135220         (in, the)       0.003126  \n",
       "2         46.409497     (Subject, Re)       0.002459  \n",
       "3         44.121113     (In, article)       0.001982  \n",
       "4         37.401619         (to, the)       0.001876  \n",
       "5         34.617501          (to, be)       0.001722  \n",
       "6         31.977423         (on, the)       0.001672  \n",
       "7         31.498479           (is, a)       0.001525  \n",
       "8         30.966998        (for, the)       0.001306  \n",
       "9         28.842104          (it, is)       0.001293  \n",
       "10        28.344194       (that, the)       0.001270  \n",
       "11        28.009625        (and, the)       0.001130  \n",
       "12        27.889612         (is, the)       0.001065  \n",
       "13        27.814304       (Lines, In)       0.001025  \n",
       "14        27.182207         (I, have)       0.000973  \n",
       "15        26.172990       (from, the)       0.000947  \n",
       "16        25.654366         (is, not)       0.000937  \n",
       "17        25.494554       (with, the)       0.000918  \n",
       "18        25.262100           (of, a)       0.000897  \n",
       "19        25.017155  (University, of)       0.000860  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pmi_df,chi_sq_df,ttest_with_filter,raw_freq_with_filter], axis=1).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed tokens: ['from', 'healta', 'saturn', 'wwc', 'edu', 'tammi', 'R', 'heali', 'subject', 'Re', 'judg', 'bobbi', 'line', 'organ', 'walla', 'walla', 'colleg', 'line', 'In', 'articl', 'apr', 'ultb', 'isc', 'rit', 'edu', 'snm', 'ultb', 'isc', 'rit', 'edu', 'S', 'N', 'mozumd', 'write', 'from', 'snm', 'ultb', 'isc', 'rit', 'edu', 'S', 'N', 'mozumd', 'subject', 'Re', 'judg', 'bobbi', 'date', 'wed', 'apr', 'gmt', 'In', 'articl', 'healta', 'saturn', 'wwc', 'edu', 'healta', 'saturn', 'wwc', 'edu', 'tammi', 'R', 'heali', 'write', 'bobbi', 'I', 'would', 'like', 'take', 'liberti', 'quot', 'christian', 'writer', 'name', 'ellen', 'G', 'white', 'I', 'hope', 'said', 'help', 'edit', 'remark', 'group', 'futur', 'Do', 'set', 'standard', 'Do', 'make', 'opinion', 'view', 'duti', 'interpret', 'scriptur', 'criterion', 'other', 'heart', 'condemn', 'come', 'ideal', 'thought', 'fromth', 'mount', 'bless', 'p', 'I', 'hope', 'quot', 'make', 'atheist', 'gag', 'I', 'think', 'ellen', 'white', 'put', 'better', 'I', 'could', 'tammi', 'point', 'peac', 'bobbi', 'mozumd', 'My', 'point', 'set', 'view', 'way', 'believ', 'say', 'eveil', 'world', 'caus', 'atheism', 'ridicul', 'counterproduct', 'dialogu', 'newsgroup', 'I', 'see', 'post', 'spirit', 'condemn', 'atheist', 'newsgroup', 'bacaus', 'believ', 'exactli', 'If', 'tri', 'convert', 'atheist', 'fail', 'miser', 'who', 'want', 'posit', 'constantli', 'defend', 'agaist', 'insult', 'attack', 'like', 'seem', 'like', 'I', 'sorri', 'blind', 'get', 'messga', 'quot', 'everyon', 'els', 'seem', 'tammi', 'from', 'jk', 'lehtori', 'cc', 'tut', 'fi', 'kouhia', 'juhana', 'subject', 'Re', 'more', 'gray', 'level', 'screen', 'organ', 'tamper', 'univers', 'technolog', 'line', 'distribut', 'inet', 'nntp']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "filtered_tokens=[]\n",
    "for token in tokens:\n",
    "    for w in token:\n",
    "        if w not in stop_words:\n",
    "            filtered_tokens.append(w)\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "stemmed_words=[]\n",
    "for w in filtered_tokens:\n",
    "    stemmed_words.append(ps.stem(w))\n",
    "    \n",
    "print(f\"Stemmed tokens: {stemmed_words[0:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3387, 1)\n",
      "(3387, 1)\n",
      "(2370, 1)\n",
      "SVC results with rbf kernel:\n",
      " [[  0   0 224   0]\n",
      " [  0   0 297   0]\n",
      " [  0   0 307   0]\n",
      " [  0   0 189   0]]\n",
      "Multinomial Naive Bayes Classifier results:\n",
      " [[221   0   2   1]\n",
      " [  1 293   3   0]\n",
      " [  0   7 300   0]\n",
      " [ 47   7  11 124]]\n"
     ]
    }
   ],
   "source": [
    "raw_data = np.array(newsgroups.data)\n",
    "raw_labels = np.array(newsgroups.target)\n",
    "\n",
    "raw_data = np.reshape(raw_data, (raw_data.shape[0],1))\n",
    "raw_labels = np.reshape(raw_labels, (raw_labels.shape[0],1))\n",
    "\n",
    "print(raw_data.shape)\n",
    "print(raw_labels.shape)\n",
    "\n",
    "newsgroups_train, newsgroups_test, newsgroups_target_train, newsgroups_target_test = train_test_split(raw_data, raw_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "print(newsgroups_train.shape)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', token_pattern='[a-zA-Z]+')\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.ravel())\n",
    "\n",
    "vectors_test = vectorizer.transform(newsgroups_test.ravel())\n",
    "\n",
    "svm_clf = SVC(gamma='auto', kernel='rbf')\n",
    "svm_clf.fit(vectors, newsgroups_target_train.ravel())\n",
    "pred = svm_clf.predict(vectors_test)\n",
    "print(f\"SVC results with rbf kernel:\\n {metrics.confusion_matrix(newsgroups_target_test.ravel(), pred)}\")\n",
    "\n",
    "\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(vectors, newsgroups_target_train.ravel())\n",
    "pred = nb_clf.predict(vectors_test)\n",
    "print(f\"Multinomial Naive Bayes Classifier results:\\n {metrics.confusion_matrix(newsgroups_target_test.ravel(), pred)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC results with linear kernel:\n",
      " [[213   0   2   9]\n",
      " [  0 297   0   0]\n",
      " [  2   9 295   1]\n",
      " [ 11   4   3 171]]\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC(gamma='auto', kernel='linear')\n",
    "svm_clf.fit(vectors, newsgroups_target_train.ravel())\n",
    "pred = svm_clf.predict(vectors_test)\n",
    "print(f\"SVC results with linear kernel:\\n {metrics.confusion_matrix(newsgroups_target_test.ravel(), pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-15 10:53:06.303945\n",
      "2019-07-15 10:54:15.350763\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'[^_\\W0-9]+')\n",
    "tokens_data = [tokenizer.tokenize(token) for token in newsgroups.data]\n",
    "pos_tagged_words_data = [nltk.pos_tag(token) for token in tokens_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_data = []\n",
    "nouns = ['NN','NNS','NNP', 'NNPS']\n",
    "\n",
    "noun_words = []\n",
    "\n",
    "for i in range(len(pos_tagged_words_data)):\n",
    "    noun_data = []\n",
    "    for j in range(len(pos_tagged_words_data[i])):\n",
    "        if (pos_tagged_words_data[i][j][1] in nouns):\n",
    "            noun_data.append(pos_tagged_words_data[i][j][0])\n",
    "    noun_words.append(noun_data)\n",
    "    \n",
    "noun_words = [\" \".join(record) for record in noun_words] \n",
    "\n",
    "# len(vectorizer.vocabulary_)\n",
    "# noun_data = list(set(noun_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC results with rbf kernel:\n",
      " 0.11593655589123868\n",
      "Multinomial Naive Bayes Classifier results:\n",
      " 0.9106626071889048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "newsgroups_noun_train, newsgroups_noun_test, newsgroups_target_noun_train, newsgroups_target_noun_test = train_test_split(noun_words, newsgroups.target, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', token_pattern='[a-zA-Z]+')\n",
    "vectors = vectorizer.fit_transform(newsgroups_noun_train)\n",
    "\n",
    "vectors_test = vectorizer.transform(newsgroups_noun_test)\n",
    "\n",
    "svm_clf = SVC(gamma='auto', kernel='rbf')\n",
    "svm_clf.fit(vectors, newsgroups_target_noun_train)\n",
    "pred = svm_clf.predict(vectors_test)\n",
    "print(f\"SVC results with rbf kernel:\\n {metrics.f1_score(newsgroups_target_noun_test, pred, average='macro')}\")\n",
    "\n",
    "\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(vectors, newsgroups_target_noun_train)\n",
    "pred = nb_clf.predict(vectors_test)\n",
    "print(f\"Multinomial Naive Bayes Classifier results:\\n {metrics.f1_score(newsgroups_target_noun_test, pred, average='macro')}\")\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(newsgroups.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
